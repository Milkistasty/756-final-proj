2024-03-15T17:55:07,016 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2024-03-15T17:55:07,016 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2024-03-15T17:55:07,045 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2024-03-15T17:55:07,045 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2024-03-15T17:55:07,046 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2024-03-15T17:55:07,046 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2024-03-15T17:55:07,085 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml
2024-03-15T17:55:07,085 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml
2024-03-15T17:55:07,165 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.10.0
TS Home: /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages
Current directory: /home/zareef/Code/756-final-proj/pose_torch_serve
Temp directory: /tmp
Metrics config path: /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 7986 M
Python executable: /home/zareef/Code/756-final-proj/env1/bin/python3
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/zareef/Code/756-final-proj/pose_torch_serve/model_store
Initial Models: keypoint_rcnn=keypoint_rcnn.mar
Log dir: /home/zareef/Code/756-final-proj/pose_torch_serve/logs
Metrics dir: /home/zareef/Code/756-final-proj/pose_torch_serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/zareef/Code/756-final-proj/pose_torch_serve/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2024-03-15T17:55:07,165 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.10.0
TS Home: /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages
Current directory: /home/zareef/Code/756-final-proj/pose_torch_serve
Temp directory: /tmp
Metrics config path: /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 7986 M
Python executable: /home/zareef/Code/756-final-proj/env1/bin/python3
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/zareef/Code/756-final-proj/pose_torch_serve/model_store
Initial Models: keypoint_rcnn=keypoint_rcnn.mar
Log dir: /home/zareef/Code/756-final-proj/pose_torch_serve/logs
Metrics dir: /home/zareef/Code/756-final-proj/pose_torch_serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/zareef/Code/756-final-proj/pose_torch_serve/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2024-03-15T17:55:07,169 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: keypoint_rcnn.mar
2024-03-15T17:55:07,169 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: keypoint_rcnn.mar
2024-03-15T17:55:08,800 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model keypoint_rcnn
2024-03-15T17:55:08,800 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model keypoint_rcnn
2024-03-15T17:55:08,800 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model keypoint_rcnn
2024-03-15T17:55:08,800 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model keypoint_rcnn
2024-03-15T17:55:08,800 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model keypoint_rcnn loaded.
2024-03-15T17:55:08,800 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model keypoint_rcnn loaded.
2024-03-15T17:55:08,800 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: keypoint_rcnn, count: 1
2024-03-15T17:55:08,800 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: keypoint_rcnn, count: 1
2024-03-15T17:55:08,807 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2024-03-15T17:55:08,806 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:08,807 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2024-03-15T17:55:08,806 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:08,844 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2024-03-15T17:55:08,844 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2024-03-15T17:55:08,845 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2024-03-15T17:55:08,845 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2024-03-15T17:55:08,845 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2024-03-15T17:55:08,845 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2024-03-15T17:55:08,846 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2024-03-15T17:55:08,846 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2024-03-15T17:55:08,846 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2024-03-15T17:55:08,846 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2024-03-15T17:55:09,005 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2024-03-15T17:55:09,005 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2024-03-15T17:55:09,038 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:55:09,038 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:55:09,573 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=12893
2024-03-15T17:55:09,573 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:55:09,573 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:55:09,573 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]12893
2024-03-15T17:55:09,574 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:55:09,574 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:55:09,574 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change null -> WORKER_STARTED
2024-03-15T17:55:09,574 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change null -> WORKER_STARTED
2024-03-15T17:55:09,576 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:09,576 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:09,581 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:55:09,583 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550509583
2024-03-15T17:55:09,583 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550509583
2024-03-15T17:55:09,584 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550509584
2024-03-15T17:55:09,584 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550509584
2024-03-15T17:55:09,600 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:55:10,736 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:55:10,737 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:55:10,737 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:55:11,265 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:55:11,265 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:55:11,265 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:55:11,265 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:55:11,265 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:55:11,265 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:55:11,265 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:55:11,266 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:55:11,267 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:55:11,267 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:55:11,267 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:55:11,267 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:55:11,313 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:11,313 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:11,313 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:11,313 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:11,313 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:11,313 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:11,328 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:11,328 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:11,328 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:11,328 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:11,328 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1710550511328
2024-03-15T17:55:11,328 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1710550511328
2024-03-15T17:55:11,329 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:11,329 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:11,329 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:11,329 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:11,329 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-03-15T17:55:11,329 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-03-15T17:55:11,371 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:11,371 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:11,371 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:11,371 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:12,331 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:12,331 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:13,053 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=12949
2024-03-15T17:55:13,054 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:55:13,059 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:55:13,059 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]12949
2024-03-15T17:55:13,059 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:55:13,059 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:55:13,059 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:13,059 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:13,059 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:13,059 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:13,061 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:55:13,061 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550513061
2024-03-15T17:55:13,061 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550513061
2024-03-15T17:55:13,061 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550513061
2024-03-15T17:55:13,061 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550513061
2024-03-15T17:55:13,069 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:55:14,218 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:55:14,218 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:55:14,218 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:55:14,724 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:55:14,724 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:55:14,724 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:55:14,725 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:55:14,726 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:55:14,726 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:55:14,726 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:55:14,726 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:55:14,771 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:14,771 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:14,772 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:14,772 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:14,772 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:14,772 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:14,772 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:14,772 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:14,772 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:14,772 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:14,772 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:14,772 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:14,773 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:14,773 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:14,773 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:14,773 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:14,773 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-03-15T17:55:14,773 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-03-15T17:55:14,812 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:14,812 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:14,812 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:14,812 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:15,774 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:15,774 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:16,501 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=12994
2024-03-15T17:55:16,501 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:55:16,507 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:55:16,507 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]12994
2024-03-15T17:55:16,507 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:55:16,507 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:55:16,507 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:16,507 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:16,507 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:16,507 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:16,508 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:55:16,508 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550516508
2024-03-15T17:55:16,508 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550516508
2024-03-15T17:55:16,508 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550516508
2024-03-15T17:55:16,508 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550516508
2024-03-15T17:55:16,517 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:55:17,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:55:17,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:55:17,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:55:18,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:55:18,243 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:55:18,288 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:18,288 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:18,288 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:18,288 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:18,288 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:18,288 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:18,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:18,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:18,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:18,289 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2024-03-15T17:55:18,289 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2024-03-15T17:55:18,328 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:18,328 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:18,328 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:18,328 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:20,290 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:20,290 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:21,006 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13044
2024-03-15T17:55:21,006 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:55:21,012 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:55:21,012 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13044
2024-03-15T17:55:21,012 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:55:21,012 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:55:21,012 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:21,012 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:21,013 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:21,013 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:21,015 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550521015
2024-03-15T17:55:21,015 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:55:21,015 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550521015
2024-03-15T17:55:21,015 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550521015
2024-03-15T17:55:21,015 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550521015
2024-03-15T17:55:21,023 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:55:22,171 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:55:22,171 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:55:22,171 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:55:22,707 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:55:22,708 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:55:22,757 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:22,757 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:22,758 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:22,758 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:22,758 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:22,758 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:22,758 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:22,758 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:22,758 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:22,758 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2024-03-15T17:55:22,758 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2024-03-15T17:55:22,797 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:22,797 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:22,797 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:22,797 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:25,759 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:25,759 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:26,492 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13095
2024-03-15T17:55:26,492 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:55:26,498 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:55:26,498 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13095
2024-03-15T17:55:26,498 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:55:26,498 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:55:26,498 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:26,498 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:26,498 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:26,498 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:26,499 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:55:26,499 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550526499
2024-03-15T17:55:26,499 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550526499
2024-03-15T17:55:26,499 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550526499
2024-03-15T17:55:26,499 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550526499
2024-03-15T17:55:26,507 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:55:27,642 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:55:27,642 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:55:27,642 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:55:28,150 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:55:28,151 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:55:28,197 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:28,197 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:28,197 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:28,197 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:28,198 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:28,198 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:28,198 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:28,198 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:28,198 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:28,198 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2024-03-15T17:55:28,198 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2024-03-15T17:55:28,244 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:28,244 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:28,244 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:28,244 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:33,199 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:33,199 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:33,933 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13193
2024-03-15T17:55:33,933 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:55:33,939 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:55:33,939 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13193
2024-03-15T17:55:33,939 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:55:33,939 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:55:33,939 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:33,939 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:33,939 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:33,939 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:33,941 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:55:33,941 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550533941
2024-03-15T17:55:33,941 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550533941
2024-03-15T17:55:33,941 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550533941
2024-03-15T17:55:33,941 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550533941
2024-03-15T17:55:33,949 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:55:35,189 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:55:35,189 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:55:35,189 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:55:35,714 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:55:35,715 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:55:35,761 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:35,761 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:35,761 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:35,761 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:35,761 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:35,761 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:35,762 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:35,762 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:35,762 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:35,762 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2024-03-15T17:55:35,762 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2024-03-15T17:55:35,816 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:35,816 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:35,816 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:35,816 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:43,763 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:43,763 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:44,495 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13287
2024-03-15T17:55:44,496 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:55:44,502 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:55:44,502 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13287
2024-03-15T17:55:44,502 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:55:44,502 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:55:44,502 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:44,502 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:55:44,502 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:44,502 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:55:44,503 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:55:44,503 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550544503
2024-03-15T17:55:44,503 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550544503
2024-03-15T17:55:44,503 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550544503
2024-03-15T17:55:44,503 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550544503
2024-03-15T17:55:44,511 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:55:45,700 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:55:45,700 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:55:45,700 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:55:46,242 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:55:46,289 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:46,289 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:55:46,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:46,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:55:46,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:46,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:55:46,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:46,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:55:46,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:46,289 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:55:46,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:46,289 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:55:46,290 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:46,290 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:46,290 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:46,290 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:46,290 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2024-03-15T17:55:46,290 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2024-03-15T17:55:46,326 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:46,326 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:55:46,326 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:46,326 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:55:59,290 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:55:59,290 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:56:00,045 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13356
2024-03-15T17:56:00,045 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:56:00,051 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:56:00,051 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13356
2024-03-15T17:56:00,051 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:56:00,051 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:56:00,051 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:56:00,051 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:56:00,051 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:56:00,051 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:56:00,053 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:56:00,053 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550560053
2024-03-15T17:56:00,053 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550560053
2024-03-15T17:56:00,053 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550560053
2024-03-15T17:56:00,053 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550560053
2024-03-15T17:56:00,061 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:56:01,175 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:56:01,175 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:56:01,175 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:56:01,694 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:56:01,695 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:56:01,739 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:56:01,739 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:56:01,740 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:56:01,740 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:56:01,740 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:56:01,740 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:56:01,740 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:56:01,740 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:01,740 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:01,740 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2024-03-15T17:56:01,740 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2024-03-15T17:56:01,778 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:01,778 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:01,778 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:01,778 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:09,052 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:56:09,052 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:56:22,742 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:56:22,742 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:56:23,461 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13495
2024-03-15T17:56:23,461 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:56:23,467 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:56:23,467 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13495
2024-03-15T17:56:23,467 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:56:23,467 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:56:23,467 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:56:23,467 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:56:23,467 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:56:23,467 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:56:23,469 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:56:23,469 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550583469
2024-03-15T17:56:23,469 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550583469
2024-03-15T17:56:23,469 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550583469
2024-03-15T17:56:23,469 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550583469
2024-03-15T17:56:23,477 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:56:24,612 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:56:24,612 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:56:24,613 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:56:25,116 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:56:25,120 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:56:25,162 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:56:25,162 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:56:25,162 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:56:25,162 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:56:25,162 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:56:25,162 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:56:25,162 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:56:25,162 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:56:25,162 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:56:25,162 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:56:25,163 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:56:25,163 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:56:25,163 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:25,163 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:25,163 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:25,163 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:25,163 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2024-03-15T17:56:25,163 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2024-03-15T17:56:25,201 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:25,201 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:56:25,201 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:25,201 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:56:56,432 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:keypoint_rcnn,model_version:default|#hostname:zareef-Legion-5-17ITH6H,timestamp:1710550616
2024-03-15T17:56:59,164 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:56:59,164 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:56:59,884 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13623
2024-03-15T17:56:59,884 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:56:59,889 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:56:59,890 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13623
2024-03-15T17:56:59,890 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:56:59,890 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:56:59,890 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:56:59,890 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:56:59,890 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:56:59,890 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:56:59,891 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:56:59,891 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550619891
2024-03-15T17:56:59,891 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550619891
2024-03-15T17:56:59,891 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550619891
2024-03-15T17:56:59,891 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550619891
2024-03-15T17:56:59,899 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:57:01,059 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:57:01,059 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:57:01,059 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:57:01,562 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:57:01,609 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:57:01,609 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:57:01,610 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:57:01,610 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:57:01,610 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:57:01,610 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:57:01,610 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:57:01,610 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:01,610 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:01,610 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2024-03-15T17:57:01,610 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2024-03-15T17:57:01,650 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:01,650 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:01,650 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:57:01,650 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:57:09,038 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:57:09,038 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:57:56,612 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:57:56,612 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:57:57,372 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13735
2024-03-15T17:57:57,372 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:57:57,379 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:57:57,380 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13735
2024-03-15T17:57:57,380 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:57:57,380 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:57:57,380 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:57:57,380 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:57:57,380 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:57:57,380 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:57:57,381 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:57:57,381 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550677381
2024-03-15T17:57:57,381 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550677381
2024-03-15T17:57:57,381 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550677381
2024-03-15T17:57:57,381 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550677381
2024-03-15T17:57:57,389 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:57:58,637 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:57:58,637 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:57:58,637 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:57:59,217 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:57:59,218 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:57:59,279 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:57:59,279 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:57:59,279 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:57:59,279 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:57:59,279 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:57:59,279 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:57:59,279 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:57:59,279 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:59,279 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:59,279 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2024-03-15T17:57:59,279 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2024-03-15T17:57:59,320 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:59,320 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:57:59,320 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:57:59,320 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:58:09,037 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:58:09,037 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:59:09,040 [ERROR] Thread-5 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:59:09,040 [ERROR] Thread-5 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T17:59:28,280 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:59:28,280 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T17:59:28,997 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=13890
2024-03-15T17:59:28,997 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T17:59:29,003 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T17:59:29,003 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]13890
2024-03-15T17:59:29,003 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T17:59:29,003 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T17:59:29,003 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:59:29,003 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T17:59:29,003 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:59:29,003 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T17:59:29,004 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T17:59:29,004 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550769004
2024-03-15T17:59:29,004 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550769004
2024-03-15T17:59:29,004 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550769004
2024-03-15T17:59:29,004 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550769004
2024-03-15T17:59:29,012 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T17:59:30,137 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T17:59:30,137 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T17:59:30,137 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T17:59:30,635 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T17:59:30,636 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T17:59:30,680 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:59:30,680 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T17:59:30,680 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:59:30,680 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T17:59:30,680 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:59:30,680 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T17:59:30,681 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:59:30,681 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:59:30,681 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:59:30,681 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2024-03-15T17:59:30,681 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2024-03-15T17:59:30,720 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:59:30,720 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T17:59:30,720 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T17:59:30,720 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T18:00:09,040 [ERROR] Thread-6 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:00:09,040 [ERROR] Thread-6 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:01:09,040 [ERROR] Thread-7 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:01:09,040 [ERROR] Thread-7 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:01:54,683 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T18:01:54,683 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/zareef/Code/756-final-proj/env1/bin/python3, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2024-03-15T18:01:55,421 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=14020
2024-03-15T18:01:55,422 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2024-03-15T18:01:55,427 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Successfully loaded /home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2024-03-15T18:01:55,428 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - [PID]14020
2024-03-15T18:01:55,428 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch worker started.
2024-03-15T18:01:55,428 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Python runtime: 3.8.10
2024-03-15T18:01:55,428 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T18:01:55,428 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-03-15T18:01:55,428 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T18:01:55,428 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2024-03-15T18:01:55,429 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2024-03-15T18:01:55,429 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550915429
2024-03-15T18:01:55,429 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1710550915429
2024-03-15T18:01:55,429 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550915429
2024-03-15T18:01:55,429 [INFO ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1710550915429
2024-03-15T18:01:55,446 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - model_name: keypoint_rcnn, batchSize: 1
2024-03-15T18:01:56,589 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-03-15T18:01:56,589 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-03-15T18:01:56,589 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Backend worker process died.
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 263, in <module>
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     worker.run_server()
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 231, in run_server
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2024-03-15T18:01:57,093 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/model_loader.py", line 143, in load
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/vision_handler.py", line 25, in initialize
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super().initialize(context)
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 170, in initialize
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     self.model = self._load_pickled_model(
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 311, in _load_pickled_model
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     model = model_class()
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -   File "/tmp/models/edd7f3e2a1bd48608d8aef845c32ddda/model.py", line 12, in __init__
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG -     super(Net, self).__init__()
2024-03-15T18:01:57,094 [INFO ] W-9000-keypoint_rcnn_1.0-stdout MODEL_LOG - TypeError: __init__() missing 1 required positional argument: 'backbone'
2024-03-15T18:01:57,142 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T18:01:57,142 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-03-15T18:01:57,142 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T18:01:57,142 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-03-15T18:01:57,143 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T18:01:57,143 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: keypoint_rcnn, error: Worker died.
2024-03-15T18:01:57,143 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T18:01:57,143 [DEBUG] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-keypoint_rcnn_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T18:01:57,143 [WARN ] W-9000-keypoint_rcnn_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T18:01:57,184 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T18:01:57,184 [INFO ] W-9000-keypoint_rcnn_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stdout
2024-03-15T18:01:57,184 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T18:01:57,184 [INFO ] W-9000-keypoint_rcnn_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-keypoint_rcnn_1.0-stderr
2024-03-15T18:02:09,035 [ERROR] Thread-8 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:02:09,035 [ERROR] Thread-8 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:03:09,040 [ERROR] Thread-9 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:03:09,040 [ERROR] Thread-9 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:04:09,040 [ERROR] Thread-10 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:04:09,040 [ERROR] Thread-10 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:05:09,052 [ERROR] Thread-11 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:05:09,052 [ERROR] Thread-11 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:06:09,039 [ERROR] Thread-12 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:06:09,039 [ERROR] Thread-12 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:07:09,038 [ERROR] Thread-13 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:07:09,038 [ERROR] Thread-13 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:08:09,044 [ERROR] Thread-14 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:08:09,044 [ERROR] Thread-14 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:09:09,044 [ERROR] Thread-15 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:09:09,044 [ERROR] Thread-15 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:10:09,043 [ERROR] Thread-16 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:10:09,043 [ERROR] Thread-16 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:11:09,038 [ERROR] Thread-17 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:11:09,038 [ERROR] Thread-17 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:12:09,051 [ERROR] Thread-18 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:12:09,051 [ERROR] Thread-18 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:13:09,050 [ERROR] Thread-19 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:13:09,050 [ERROR] Thread-19 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:14:09,052 [ERROR] Thread-20 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:14:09,052 [ERROR] Thread-20 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:15:09,051 [ERROR] Thread-21 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:15:09,051 [ERROR] Thread-21 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:16:09,040 [ERROR] Thread-22 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:16:09,040 [ERROR] Thread-22 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:17:09,048 [ERROR] Thread-23 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:17:09,048 [ERROR] Thread-23 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:18:09,041 [ERROR] Thread-24 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:18:09,041 [ERROR] Thread-24 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:19:09,035 [ERROR] Thread-25 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:19:09,035 [ERROR] Thread-25 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:20:09,040 [ERROR] Thread-26 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:20:09,040 [ERROR] Thread-26 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:21:09,039 [ERROR] Thread-27 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:21:09,039 [ERROR] Thread-27 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:22:09,038 [ERROR] Thread-28 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:22:09,038 [ERROR] Thread-28 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:23:09,049 [ERROR] Thread-29 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:23:09,049 [ERROR] Thread-29 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:24:09,050 [ERROR] Thread-30 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:24:09,050 [ERROR] Thread-30 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:25:09,040 [ERROR] Thread-31 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:25:09,040 [ERROR] Thread-31 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:26:09,052 [ERROR] Thread-32 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:26:09,052 [ERROR] Thread-32 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:27:09,038 [ERROR] Thread-33 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:27:09,038 [ERROR] Thread-33 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:28:09,039 [ERROR] Thread-34 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:28:09,039 [ERROR] Thread-34 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:29:09,052 [ERROR] Thread-35 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:29:09,052 [ERROR] Thread-35 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:30:09,040 [ERROR] Thread-36 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:30:09,040 [ERROR] Thread-36 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:31:09,052 [ERROR] Thread-37 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:31:09,052 [ERROR] Thread-37 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:32:09,040 [ERROR] Thread-38 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:32:09,040 [ERROR] Thread-38 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:33:09,051 [ERROR] Thread-39 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:33:09,051 [ERROR] Thread-39 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:34:09,041 [ERROR] Thread-40 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:34:09,041 [ERROR] Thread-40 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:35:09,039 [ERROR] Thread-41 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:35:09,039 [ERROR] Thread-41 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:36:09,049 [ERROR] Thread-42 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:36:09,049 [ERROR] Thread-42 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:37:09,039 [ERROR] Thread-43 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:37:09,039 [ERROR] Thread-43 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:38:09,035 [ERROR] Thread-44 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:38:09,035 [ERROR] Thread-44 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:39:09,040 [ERROR] Thread-45 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:39:09,040 [ERROR] Thread-45 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:40:09,040 [ERROR] Thread-46 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:41:09,052 [ERROR] Thread-47 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:42:09,051 [ERROR] Thread-48 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:43:09,042 [ERROR] Thread-49 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:44:09,039 [ERROR] Thread-50 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:45:09,051 [ERROR] Thread-51 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:46:09,042 [ERROR] Thread-52 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:47:09,036 [ERROR] Thread-53 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:48:09,039 [ERROR] Thread-54 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:49:09,041 [ERROR] Thread-55 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:50:09,052 [ERROR] Thread-56 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:51:09,038 [ERROR] Thread-57 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:52:09,040 [ERROR] Thread-58 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:53:09,052 [ERROR] Thread-59 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:54:09,039 [ERROR] Thread-60 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:55:09,039 [ERROR] Thread-61 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:56:09,042 [ERROR] Thread-62 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:57:09,039 [ERROR] Thread-63 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:58:09,041 [ERROR] Thread-64 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T18:59:09,038 [ERROR] Thread-65 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T19:00:09,036 [ERROR] Thread-66 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T19:01:09,051 [ERROR] Thread-67 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T19:02:09,039 [ERROR] Thread-68 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-03-15T19:03:09,040 [ERROR] Thread-69 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "ts/metrics/metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "/home/zareef/Code/756-final-proj/env1/lib/python3.8/site-packages/ts/metrics/system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

